{"cells":[{"cell_type":"code","execution_count":241,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"X-j1XuemlitM","executionInfo":{"status":"ok","timestamp":1649330906118,"user_tz":-270,"elapsed":382,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}},"outputId":"0897c078-da38-497e-a8af-3ee2f35f186a"},"outputs":[{"output_type":"display_data","data":{"application/javascript":["IPython.notebook.set_autosave_interval(180000)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Autosaving every 180 seconds\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import torch.nn.functional as F\n","import numpy as np\n","import itertools\n","import pickle\n","%autosave 180"]},{"cell_type":"code","execution_count":242,"metadata":{"id":"EaUG27Njlitc","executionInfo":{"status":"ok","timestamp":1649330906755,"user_tz":-270,"elapsed":37,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}}},"outputs":[],"source":["# This will be our input\n","\n","text = 'MoriMoriMoriMoriMori'"]},{"cell_type":"code","execution_count":243,"metadata":{"id":"FvqNO81xlite","executionInfo":{"status":"ok","timestamp":1649330906756,"user_tz":-270,"elapsed":35,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}}},"outputs":[],"source":["character_list = list(set(text))   # get all of the unique letters in our text variable\n","vocabulary_size = len(character_list)   # count the number of unique elements\n","character_dictionary = {'i': 0, 'o': 1, 'r': 2, 'M': 3}\n","# {char:e for e, char in enumerate(character_list)}  # create a dictionary mapping each unique char to a number\n","encoded_chars = [character_dictionary[char] for char in text] #integer representation of our vocabulary "]},{"cell_type":"code","execution_count":244,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Kr_zagclitf","executionInfo":{"status":"ok","timestamp":1649330906757,"user_tz":-270,"elapsed":36,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}},"outputId":"d96586af-f2a4-4b2c-b4a5-d7e42167ecfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'i': 0, 'o': 1, 'r': 2, 'M': 3}\n"]}],"source":["print(character_dictionary)"]},{"cell_type":"code","execution_count":245,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6mi8OyQlitf","executionInfo":{"status":"ok","timestamp":1649330906758,"user_tz":-270,"elapsed":34,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}},"outputId":"7936a6ec-8119-4f6c-eda3-de44d0115bc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 1, 2, 0, 3, 1, 2, 0, 3, 1, 2, 0, 3, 1, 2, 0, 3, 1, 2, 0]\n"]}],"source":["print(encoded_chars)"]},{"cell_type":"code","execution_count":246,"metadata":{"id":"iQqiN63Zlitl","executionInfo":{"status":"ok","timestamp":1649330906760,"user_tz":-270,"elapsed":33,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}}},"outputs":[],"source":["def one_hot_encode(encoded, vocab_size):\n","    result = torch.zeros((len(encoded), vocab_size))\n","    for i, idx in enumerate(encoded):\n","        result[i, idx] = 1.0\n","    return result"]},{"cell_type":"code","execution_count":247,"metadata":{"id":"zs6MI5_Wlitm","executionInfo":{"status":"ok","timestamp":1649330906761,"user_tz":-270,"elapsed":33,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}}},"outputs":[],"source":["# One hot encode our encoded charactes\n","batch_size = 2\n","seq_length = 3\n","num_samples = (len(encoded_chars) - 1) // seq_length # time lag of 1 for creating the labels\n","vocab_size = 4\n","\n","data = one_hot_encode(encoded_chars[:seq_length*num_samples], vocab_size).reshape((num_samples, seq_length, vocab_size))\n","num_batches = len(data) // batch_size\n","X = data[:num_batches*batch_size].reshape((num_batches, batch_size, seq_length, vocab_size))\n","# swap batch_size and seq_length axis to make later access easier\n","X = X.transpose(1, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22jmR5PClitp"},"outputs":[],"source":["labels = one_hot_encode(encoded_chars[1:seq_length*num_samples+1], vocab_size) \n","y = labels.reshape((num_batches, batch_size, seq_length, vocab_size))\n","y = y.transpose(1, 2) \n","y,y.shape"]},{"cell_type":"code","execution_count":249,"metadata":{"id":"mZDax66ulitt","executionInfo":{"status":"ok","timestamp":1649330906763,"user_tz":-270,"elapsed":32,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}}},"outputs":[],"source":["torch.manual_seed(1) # reproducibility\n","\n","####  Define the network parameters:\n","hiddenSize = 2 # network size, this can be any number (depending on your task)\n","numClass = 4 # this is the same as our vocab_size\n","\n","#### Weight matrices for our inputs \n","Wz = Variable(torch.randn(vocab_size, hiddenSize), requires_grad=False)\n","Wr = Variable(torch.randn(vocab_size, hiddenSize), requires_grad=False)\n","Wh = Variable(torch.randn(vocab_size, hiddenSize), requires_grad=False)\n","\n","## Intialize the hidden state\n","# this is for demonstration purposes only, in the actual model it will be initiated during training a loop over the \n","# the number of bacthes and updated before passing to the next GRU cell.\n","h_t_demo = torch.zeros(batch_size, hiddenSize) \n","\n","#### Weight matrices for our hidden layer\n","Uz = Variable(torch.randn(hiddenSize, hiddenSize), requires_grad=False)\n","Ur = Variable(torch.randn(hiddenSize, hiddenSize), requires_grad=False)\n","Uh = Variable(torch.randn(hiddenSize, hiddenSize), requires_grad=False)\n","\n","#### bias vectors for our hidden layer\n","bz = Variable(torch.zeros(hiddenSize), requires_grad=False)\n","br = Variable(torch.zeros(hiddenSize), requires_grad=False)\n","bh = Variable(torch.zeros(hiddenSize), requires_grad=False)\n","\n","#### Output weights\n","Wy = Variable(torch.randn(hiddenSize, numClass), requires_grad=False)\n","by = Variable(torch.zeros(numClass), requires_grad=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCfgG2HnliuE"},"outputs":[],"source":["# h gets updated and then we calculate for the next \n","h_t_1 = []\n","h = h_t_demo\n","for i,sequence in enumerate(X[0]):   # iterate over each sequence in the batch to calculate the hidden state h \n","    z = torch.sigmoid(torch.matmul(sequence, Wz) + torch.matmul(h, Uz) + bz)\n","    r = torch.sigmoid(torch.matmul(sequence, Wr) + torch.matmul(h, Ur) + br)\n","    h_tilde = torch.tanh(torch.matmul(sequence, Wh) + torch.matmul(r * h, Uh) + bh)\n","    h = z * h + (1 - z) * h_tilde\n","    h_t_1.append(h)\n","    print(f'h{i}:{h}')\n","h_t_1 = torch.stack(h_t_1)"]},{"cell_type":"code","execution_count":251,"metadata":{"id":"-7VVCipQliuU","executionInfo":{"status":"ok","timestamp":1649330906765,"user_tz":-270,"elapsed":28,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}}},"outputs":[],"source":["def gru(x, h):\n","    outputs = []\n","    for i,sequence in enumerate(x): # iterates over the sequences in each batch\n","        z = torch.sigmoid(torch.matmul(sequence, Wz) + torch.matmul(h, Uz) + bz)\n","        r = torch.sigmoid(torch.matmul(sequence, Wr) + torch.matmul(h, Ur) + br)\n","        h_tilde = torch.tanh(torch.matmul(sequence, Wh) + torch.matmul(r * h, Uh) + bh)\n","        h = z * h + (1 - z) * h_tilde\n","\n","        # Linear layer\n","        y_linear = torch.matmul(h, Wy) + by\n","\n","        # Softmax activation function\n","        y_t = F.softmax(y_linear, dim=1)\n","\n","        outputs.append(y_t)\n","    return torch.stack(outputs), h\n","    "]},{"cell_type":"code","execution_count":252,"metadata":{"id":"F4MM20_6liuV","executionInfo":{"status":"ok","timestamp":1649330906766,"user_tz":-270,"elapsed":29,"user":{"displayName":"mori cyberdh","userId":"10949376291156896152"}}},"outputs":[],"source":["def sample(primer, length_chars_predict):\n","    \n","    word = primer\n","\n","    primer_dictionary = [character_dictionary[char] for char in word]\n","    test_input = one_hot_encode(primer_dictionary, vocab_size)\n","    \n","\n","    h = torch.zeros(1, hiddenSize)\n","\n","    for i in range(length_chars_predict):\n","        outputs, h = gru(test_input, h)\n","        choice = np.random.choice(vocab_size, p=outputs[-1][0].numpy())\n","        word += character_list[choice]\n","        input_sequence = one_hot_encode([choice],vocab_size)\n","    return word\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1HV9an5OliuW"},"outputs":[],"source":["max_epochs = 20  # passes through the data\n","for e in range(max_epochs):\n","    h = torch.zeros(batch_size, hiddenSize)\n","    for i in range(num_batches):\n","        x_in = X[i]\n","        y_in = y[i]\n","        \n","        out, h = gru(x, h)\n","        print(sample('Mo',20))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"GRU_from _Scratch.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}